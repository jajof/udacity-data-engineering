{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We create the tables\n",
    "Execution of the first step: Drop the table if exists and create the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS staging_events \n",
      "\n",
      "DROP TABLE IF EXISTS staging_songs \n",
      "\n",
      "DROP TABLE IF EXISTS fact_songplay \n",
      "\n",
      "DROP TABLE IF EXISTS dim_users \n",
      "\n",
      "DROP TABLE IF EXISTS dim_songs \n",
      "\n",
      "DROP TABLE IF EXISTS dim_artists \n",
      "\n",
      "DROP TABLE IF EXISTS dim_time \n",
      "\n",
      "CREATE TABLE staging_events (\n",
      "                                  artist text,\n",
      "                                  auth text,\n",
      "                                  first_name text,\n",
      "                                  gender text,\n",
      "                                  itemInSession int,\n",
      "                                  lastName text,\n",
      "                                  lenght DOUBLE PRECISION,\n",
      "                                  level text,\n",
      "                                  location text,\n",
      "                                  method text,\n",
      "                                  page text,\n",
      "                                  registration bigint,\n",
      "                                  sessionId int,\n",
      "                                  song text,\n",
      "                                  status int,\n",
      "                                  ts bigint,\n",
      "                                  userAgent text,\n",
      "                                  UserId int\n",
      "                                ) \n",
      "\n",
      "CREATE TABLE staging_songs  (\n",
      "                                  artist_id text,\n",
      "                                  artist_latitude DOUBLE PRECISION,\n",
      "                                  artist_location text,\n",
      "                                  artist_longitude DOUBLE PRECISION,\n",
      "                                  artist_name text,\n",
      "                                  duration DOUBLE PRECISION,\n",
      "                                  num_songs int,\n",
      "                                  song_id text,\n",
      "                                  title text,\n",
      "                                  year int\n",
      "                                ) \n",
      "\n",
      "CREATE TABLE dim_users (\n",
      "                        user_id INT NOT NULL,\n",
      "                        level TEXT NOT NULL, \n",
      "                        first_name text, \n",
      "                        last_name text, \n",
      "                        gender text,\n",
      "                        PRIMARY KEY (user_id, level)\n",
      "                    ) \n",
      "\n",
      "CREATE TABLE dim_artists (\n",
      "                          artist_id TEXT NOT NULL PRIMARY KEY, \n",
      "                          name TEXT,  \n",
      "                          location TEXT, \n",
      "                          lattitude DOUBLE PRECISION, \n",
      "                          longitude DOUBLE PRECISION\n",
      "                        ) \n",
      "\n",
      "CREATE TABLE dim_songs (\n",
      "                        song_id text NOT NULL PRIMARY KEY, \n",
      "                        title text, \n",
      "                        artist_id TEXT NOT NULL REFERENCES dim_artists(artist_id), \n",
      "                        year int, \n",
      "                        duration DOUBLE PRECISION\n",
      "                    ) \n",
      "\n",
      "CREATE TABLE dim_time (\n",
      "                        start_time dateTime NOT NULL PRIMARY KEY,\n",
      "                        hour int NOT NULL,\n",
      "                        day int NOT NULL,\n",
      "                        week int NOT NULL,\n",
      "                        month int NOT NULL,\n",
      "                        year int NOT NULL,\n",
      "                        weekday int NOT NULL\n",
      "                    ) \n",
      "\n",
      "CREATE TABLE fact_songplay (\n",
      "                            songplay_id INT NOT NULL IDENTITY(1,1) PRIMARY KEY, \n",
      "                            start_time DATE NOT NULL REFERENCES dim_time(start_time), \n",
      "                            user_id INT NOT NULL, \n",
      "                            level TEXT NOT NULL, \n",
      "                            song_id TEXT NULL REFERENCES dim_songs(song_id), \n",
      "                            artist_id TEXT NULL REFERENCES dim_artists(artist_id), \n",
      "                            session_id int NOT NULL, \n",
      "                            location TEXT, \n",
      "                            user_agent TEXT,\n",
      "                            foreign key(user_id, level) references dim_users(user_id, level))\n",
      "                         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python 1_create_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the ETL\n",
    "The second step is take the data into the staging tables and later insert it into the star-schema tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into staging tables...\n",
      "copy staging_events \n",
      "                           from 's3://udacity-dend/log_data'\n",
      "                           credentials 'aws_iam_role=arn:aws:iam::276425435005:role/dwhRole'\n",
      "                           json 's3://udacity-dend/log_json_path.json' \n",
      "                           region 'us-west-2';\n",
      "                        \n",
      "copy staging_songs from 's3://udacity-dend/song_data'\n",
      "                           credentials 'aws_iam_role=arn:aws:iam::276425435005:role/dwhRole'\n",
      "                           json 'auto ignorecase'\n",
      "                           region 'us-west-2';\n",
      "                        \n",
      "Inserting data into definitive tables...\n",
      "INSERT INTO dim_users (user_id, level, first_name, last_name, gender)\n",
      "                        Select distinct\n",
      "                            userid,\n",
      "                            level,\n",
      "                            first_name,\n",
      "                            lastname,\n",
      "                            gender\n",
      "                        FROM staging_events\n",
      "                        where userid is not NULL\n",
      "\n",
      "INSERT INTO dim_songs (song_id, title, artist_id, year, duration) \n",
      "                        Select distinct\n",
      "                            song_id,\n",
      "                            title,\n",
      "                            artist_id,\n",
      "                            year,\n",
      "                            duration\n",
      "                        FROM staging_songs\n",
      "                    \n",
      "INSERT INTO dim_artists (artist_id, name, location, lattitude, longitude)\n",
      "                          Select distinct\n",
      "                              artist_id, \n",
      "                              artist_name,\n",
      "                              artist_location,\n",
      "                              artist_latitude,\n",
      "                              artist_longitude\n",
      "                          FROM staging_songs\n",
      "                        \n",
      "INSERT INTO dim_time (start_time, hour, day, week, month, year, weekday)\n",
      "                        Select distinct\n",
      "                            start_time,\n",
      "                            EXTRACT(hour FROM start_time),\n",
      "                            EXTRACT(day FROM start_time),\n",
      "                            EXTRACT(week FROM start_time),\n",
      "                            EXTRACT(month FROM start_time),\n",
      "                            EXTRACT(year FROM start_time),\n",
      "                            EXTRACT(weekday FROM start_time)\n",
      "                        FROM \n",
      "                            (SELECT TIMESTAMP 'epoch' + ts/1000 * INTERVAL '1 second' AS start_time\n",
      "                            FROM staging_Events\n",
      "                            where page = 'NextSong') a\n",
      "                                \n",
      "INSERT INTO fact_songplay (start_time, user_id, level, song_id, artist_id, \n",
      "                                                       session_id,location,user_agent)\n",
      "                            SELECT \n",
      "                                TIMESTAMP 'epoch' + ts/1000 * INTERVAL '1 second' AS start_time,\n",
      "                                e.userid,\n",
      "                                e.level,\n",
      "                                s.song_id,\n",
      "                                s.artist_id,\n",
      "                                e.sessionid,\n",
      "                                e.location,\n",
      "                                e.useragent                        \n",
      "                            FROM \n",
      "                                staging_Events e\n",
      "                                LEFT  JOIN staging_songs s on s.title = e.song and e.artist = s.artist_name\n",
      "                            where page = 'NextSong';\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "!python 2_etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Finally, we execute some additional queries to check the data is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the number of rows of each table...\n",
      "SELECT COUNT(*) from staging_events\n",
      "[(8056,)]\n",
      "\n",
      "SELECT COUNT(*) from staging_songs\n",
      "[(14896,)]\n",
      "\n",
      "SELECT COUNT(*) from dim_time\n",
      "[(6813,)]\n",
      "\n",
      "SELECT COUNT(*) from dim_users\n",
      "[(105,)]\n",
      "\n",
      "SELECT COUNT(*) from dim_artists\n",
      "[(10025,)]\n",
      "\n",
      "SELECT COUNT(*) from dim_songs\n",
      "[(14896,)]\n",
      "\n",
      "SELECT COUNT(*) from fact_songplay\n",
      "[(6820,)]\n",
      "\n",
      "Solving some example questions...\n",
      "1. How many active users are there in the app?\n",
      "Select count(DISTINCT USER_ID) FROM DIM_USERS\n",
      "(97,)\n",
      "\n",
      "2. What is the location with more reproductions?\n",
      "\n",
      "            Select location, count(*) \n",
      "            from fact_songplay\n",
      "            group by location\n",
      "            order by 2 desc\n",
      "            limit 1\n",
      "('San Francisco-Oakland-Hayward, CA', 691)\n",
      "\n",
      "3. Build a ranking with the users with more reproductions in the app\n",
      "\n",
      "            SELECT\n",
      "                f.user_id, u.first_name, u.last_name, count(*)\n",
      "            FROM\n",
      "                fact_songplay f\n",
      "                inner join dim_users u on u.user_id = f.user_id\n",
      "            group by \n",
      "                f.user_id, u.first_name, u.last_name\n",
      "            order by 4 desc\n",
      "            limit 10\n",
      "\n",
      "\n",
      "(49, 'Chloe', 'Cuevas', 1378)\n",
      "(80, 'Tegan', 'Levine', 1330)\n",
      "(15, 'Lily', 'Koch', 926)\n",
      "(29, 'Jacqueline', 'Lynch', 692)\n",
      "(97, 'Kate', 'Harrell', 557)\n",
      "(88, 'Mohammad', 'Rodriguez', 540)\n",
      "(36, 'Matthew', 'Jones', 496)\n",
      "(16, 'Rylan', 'George', 446)\n",
      "(44, 'Aleena', 'Kirby', 397)\n",
      "(85, 'Kinsley', 'Young', 358)\n",
      "\n",
      "4. What is the date range we are working on\n",
      "\n",
      "        Select\n",
      "            min(start_time), max(start_time)\n",
      "        from\n",
      "            fact_songplay f;\n",
      "\n",
      "(datetime.datetime(2018, 11, 1, 21, 1, 46), datetime.datetime(2018, 11, 30, 19, 54, 24))\n",
      "\n",
      "5. How many reproductions are in each hour?\n",
      "\n",
      "        Select \n",
      "            Hour,\n",
      "            count(*)\n",
      "        from \n",
      "            fact_songplay f inner join \n",
      "            dim_time t on f.start_time = t.start_time\n",
      "        group by Hour\n",
      "        order by 1 asc\n",
      "\n",
      "(0, 155)\n",
      "(1, 154)\n",
      "(2, 117)\n",
      "(3, 109)\n",
      "(4, 136)\n",
      "(5, 162)\n",
      "(6, 183)\n",
      "(7, 179)\n",
      "(8, 207)\n",
      "(9, 270)\n",
      "(10, 312)\n",
      "(11, 336)\n",
      "(12, 308)\n",
      "(13, 324)\n",
      "(14, 432)\n",
      "(15, 477)\n",
      "(16, 542)\n",
      "(17, 494)\n",
      "(18, 498)\n",
      "(19, 367)\n",
      "(20, 360)\n",
      "(21, 280)\n",
      "(22, 217)\n",
      "(23, 201)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python 3_analysis.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
